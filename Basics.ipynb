{"cells":[{"cell_type":"code","source":["# import required libraries\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.datasets import load_digits\n","from sklearn.metrics import silhouette_score\n","from collections import Counter"],"metadata":{"id":"xZ_Qh0i-yGap","executionInfo":{"status":"ok","timestamp":1761889255634,"user_tz":240,"elapsed":4458,"user":{"displayName":"I S","userId":"12967859421107806184"}}},"id":"xZ_Qh0i-yGap","execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load the digits dataset\n","digits = load_digits()\n","X = digits.data\n","y = digits.target\n","print(X.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GdqexgIfyApT","executionInfo":{"status":"ok","timestamp":1761889256993,"user_tz":240,"elapsed":22,"user":{"displayName":"I S","userId":"12967859421107806184"}},"outputId":"635c8006-89c3-4f9d-9e95-6e78e0e7165d"},"id":"GdqexgIfyApT","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(1797, 64) (1797,)\n"]}]},{"cell_type":"code","execution_count":10,"id":"e445adaa-18b1-4641-a04c-c487392e1931","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e445adaa-18b1-4641-a04c-c487392e1931","executionInfo":{"status":"ok","timestamp":1761889408909,"user_tz":240,"elapsed":8,"user":{"displayName":"I S","userId":"12967859421107806184"}},"outputId":"ebe41a29-a286-4f64-ed92-3b904b49680f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of samples in train data (1437,)\n","Number of samples in test data (360,)\n","\n","Shape of training data (1437, 64)\n","Shape of testing data (360, 64)\n"]}],"source":["# normalize the data, so values are between 0 and 1\n","X = X / 16.0\n","\n","# setting a random seed so we get same results everytime\n","np.random.seed(42)\n","\n","# list of indices for all samples\n","indices = np.arange(len(X))\n","\n","# shuffle indices randomly\n","np.random.shuffle(indices)\n","\n","# separate the 80% of dataset into training\n","split = int(0.8 * len(X))\n","\n","# first 80% of the sample used for training\n","train_indices = indices[:split]\n","# remaining 20% of the samples for testing\n","test_indices = indices[split:]\n","\n","# create training and testing datasets\n","X_train = X[train_indices]\n","y_train = y[train_indices]\n","X_test = X[test_indices]\n","y_test = y[test_indices]\n","\n","\n","print(f\"Number of samples in train data {train_indices.shape}\")\n","print(f\"Number of samples in test data {test_indices.shape}\\n\")\n","print(f\"Shape of training data {X_train.shape}\")\n","print(f\"Shape of testing data {X_test.shape}\")"]},{"cell_type":"code","source":["import numpy as np\n","\n","classes = np.unique(y_train)\n","\n","means = {}\n","variances = {}\n","priors = {}\n","\n","for c in classes:\n","    X_c = X_train[y_train == c]\n","    means[c] = X_c.mean(axis=0)\n","    variances[c] = X_c.var(axis=0)\n","    priors[c] = len(X_c) / len(X_train)\n","def gaussian_pdf(x, mean, var):\n","    eps = 1e-9  # to avoid division by zero\n","    coeff = 1.0 / np.sqrt(2.0 * np.pi * var + eps)\n","    exponent = np.exp(-((x - mean)**2) / (2 * var + eps))\n","    return coeff * exponent\n","def predict_one(x):\n","    posteriors = []\n","    for c in classes:\n","        # log prior\n","        log_prior = np.log(priors[c])\n","        # log likelihoods\n","        log_likelihood = np.sum(np.log(gaussian_pdf(x, means[c], variances[c])))\n","        # posterior\n","        posterior = log_prior + log_likelihood\n","        posteriors.append(posterior)\n","    return classes[np.argmax(posteriors)]\n","\n","# Predict for all test samples\n","y_pred = np.array([predict_one(x) for x in X_test])\n","accuracy = np.mean(y_pred == y_test)\n","print(f\"Naive Bayes Test Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYr3cp06zTqf","executionInfo":{"status":"ok","timestamp":1761889589046,"user_tz":240,"elapsed":106,"user":{"displayName":"I S","userId":"12967859421107806184"}},"outputId":"50e64675-5c1d-4b00-9fe8-78bb5b90b2ee"},"id":"PYr3cp06zTqf","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes Test Accuracy: 84.17%\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4224545780.py:25: RuntimeWarning: divide by zero encountered in log\n","  log_likelihood = np.sum(np.log(gaussian_pdf(x, means[c], variances[c])))\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","class NaiveBayes:\n","\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","        self._classes = np.unique(y)\n","        n_classes = len(self._classes)\n","\n","        # calculate mean, var, and prior for each class\n","        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._priors = np.zeros(n_classes, dtype=np.float64)\n","\n","        for idx, c in enumerate(self._classes):\n","            X_c = X[y == c]\n","            self._mean[idx, :] = X_c.mean(axis=0)\n","            self._var[idx, :] = X_c.var(axis=0)\n","            self._priors[idx] = X_c.shape[0] / float(n_samples)\n","\n","\n","    def predict(self, X):\n","        y_pred = [self._predict(x) for x in X]\n","        return np.array(y_pred)\n","\n","    def _predict(self, x):\n","        posteriors = []\n","\n","        # calculate posterior probability for each class\n","        for idx, c in enumerate(self._classes):\n","            prior = np.log(self._priors[idx])\n","            posterior = np.sum(np.log(self._pdf(idx, x)))\n","            posterior = posterior + prior\n","            posteriors.append(posterior)\n","\n","        # return class with the highest posterior\n","        return self._classes[np.argmax(posteriors)]\n","\n","    def _pdf(self, class_idx, x):\n","        mean = self._mean[class_idx]\n","        var = self._var[class_idx]\n","        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n","        denominator = np.sqrt(2 * np.pi * var)\n","        return numerator / denominator\n","\n","# create the model\n","nb = NaiveBayes()\n","# train the model using training data\n","nb.fit(X_train, y_train)\n","# predict labels for test data\n","predictions = nb.predict(X_test)\n","\n","# compute and print accuracy\n","accuracy = np.sum(predictions == y_test) / len(y_test) * 100\n","print(f\"Accuracy of test data: {accuracy:.2f} %\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"colYTlqxxl4h","executionInfo":{"status":"ok","timestamp":1761889411307,"user_tz":240,"elapsed":84,"user":{"displayName":"I S","userId":"12967859421107806184"}},"outputId":"93489f80-1219-4688-a28d-ec53fbd02445"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of test data: 12.22 %\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3204114779.py:42: RuntimeWarning: divide by zero encountered in divide\n","  numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n","/tmp/ipython-input-3204114779.py:42: RuntimeWarning: invalid value encountered in divide\n","  numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n","/tmp/ipython-input-3204114779.py:44: RuntimeWarning: invalid value encountered in divide\n","  return numerator / denominator\n","/tmp/ipython-input-3204114779.py:32: RuntimeWarning: divide by zero encountered in log\n","  posterior = np.sum(np.log(self._pdf(idx, x)))\n"]}],"id":"colYTlqxxl4h"}],"metadata":{"kernelspec":{"display_name":"Python [conda env:anaconda3] *","language":"python","name":"conda-env-anaconda3-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}